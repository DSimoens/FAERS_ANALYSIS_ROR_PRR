{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d2186-a124-4780-90c5-d96264256da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EudraVigilance Line Listing Analysis with VigiMatch-style Deduplication\n",
    "# Author: Djamilla Simoens (2025)\n",
    "# Version: 1.0 \n",
    "\n",
    "# =============================\n",
    "# Install Dependencies\n",
    "# =============================\n",
    "\n",
    "# In Jupyter Notebook, run this cell first only when needed:\n",
    "!pip install pandas numpy scipy openpyxl tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cbb240-7c63-4b57-80f6-68725c62c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Import Libraries\n",
    "# =============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import fisher_exact, chi2_contingency\n",
    "from tqdm import tqdm\n",
    "from hashlib import sha256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf019c51-4f19-45a5-80ac-16bde7e7841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Load excel document \n",
    "# =============================\n",
    "file_path = \"eudravigilance_line_listing.xlsx\"  # Replace with your file\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "print(f\"Loaded {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19416d0-d241-4e82-b983-b8cb9d46f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# 4. Preprocess Columns\n",
    "# =============================\n",
    "# Normalize column names\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "\n",
    "# Normalize textual content\n",
    "\n",
    "def normalize(text):\n",
    "    return str(text).strip().lower()\n",
    "\n",
    "# If reaction terms are grouped with ';', split them later\n",
    "df['reaction_term'] = df['reaction_term'].apply(normalize)\n",
    "df['drug_name'] = df['drug_name'].apply(normalize)\n",
    "df['sex'] = df['sex'].apply(normalize)\n",
    "\n",
    "# =============================\n",
    "# 5. Create VigiMatch-style Deduplication Key\n",
    "# =============================\n",
    "def create_match_key(row):\n",
    "    components = [\n",
    "        str(row.get('age', '')),\n",
    "        str(row.get('sex', '')),\n",
    "        str(row.get('drug_name', '')),\n",
    "        str(row.get('reaction_term', '')),\n",
    "        str(row.get('reporter_country', '')),\n",
    "        str(row.get('reported_date', ''))[:10],  # Date only\n",
    "    ]\n",
    "    key_string = \"|\".join(components)\n",
    "    return sha256(key_string.encode()).hexdigest()\n",
    "\n",
    "df['match_key'] = df.apply(create_match_key, axis=1)\n",
    "\n",
    "# =============================\n",
    "# 6. Deduplicate Records\n",
    "# =============================\n",
    "df_dedup = df.drop_duplicates(subset=['match_key'])\n",
    "\n",
    "print(f\"\\n Duplicates Removed {len(df) - len(df_dedup)} duplicate reports\")\n",
    "print(f\" Deduplicated count: {len(df_dedup)}\")\n",
    "\n",
    "# =============================\n",
    "# 7. Split reaction terms into individual rows\n",
    "# =============================\n",
    "reaction_split = (\n",
    "    df_dedup.assign(reaction_term=df_dedup['reaction_term'].str.split(';'))\n",
    "    .explode('reaction_term')\n",
    ")\n",
    "reaction_split['reaction_term'] = reaction_split['reaction_term'].str.strip()\n",
    "\n",
    "# 8. Basic Analysis\n",
    "print(\"\\nReaction term counts:\")\n",
    "all_reactions = reaction_split['reaction_term'].value_counts()\n",
    "print(all_reactions)\n",
    "\n",
    "if 'serious' in reaction_split.columns:\n",
    "    print(\"\\nSerious vs. Non-serious:\")\n",
    "    seriousness_counts = reaction_split['serious'].value_counts()\n",
    "    print(seriousness_counts)\n",
    "else:\n",
    "    seriousness_counts = pd.Series(dtype=int)\n",
    "\n",
    "# 9. Export Deduplicated File\n",
    "with pd.ExcelWriter(\"deduplicated_output.xlsx\") as writer:\n",
    "    df_dedup.to_excel(writer, sheet_name=\"Deduplicated Data\", index=False)\n",
    "    reaction_split.to_excel(writer, sheet_name=\"Expanded Reactions\", index=False)\n",
    "    all_reactions.to_frame(name=\"count\").to_excel(writer, sheet_name=\"Reaction Counts\")\n",
    "    seriousness_counts.to_frame(name=\"count\").to_excel(writer, sheet_name=\"Seriousness Summary\")\n",
    "\n",
    "print(\"\\n Exported deduplicated data and analysis to 'deduplicated_output.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa2db5-cad4-45ba-87d2-f31e966cd903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
