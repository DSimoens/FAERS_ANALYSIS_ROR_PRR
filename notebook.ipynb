# FAERS Disproportionality Analysis Pipeline
# Version v1.0
# Djamilla Simoens

# =============================
# 1️⃣ Install Dependencies
# =============================

# In Jupyter Notebook, run this cell first:
!pip install pandas numpy scipy openpyxl tqdm

# =============================
# 2️⃣ Import Libraries
# =============================

import pandas as pd
import numpy as np
import os
import glob
from scipy.stats import fisher_exact, chi2_contingency
from tqdm import tqdm

# =============================
# 3️⃣ User Input
# =============================
# Type the name of the drug and adverse reactions of interest

drug_synonyms = ['LUXTURNA', 'VORETIGENE NEPARVOVEC']
event_synonyms = ['Retinal degeneration', 'RETINAL ATROPHY', 'FOVEAL ATROPHY', 'RETINAL DEPIGMENTATION', 'INJECTION SITE ATROPHY']
data_dir = './faers_data'  # Update with your FAERS TXT folder

# =============================
# 4️⃣ Load and Concatenate FAERS Data
# =============================

def load_files(folder, pattern):
    files = sorted(glob.glob(os.path.join(folder, pattern)))
    dfs = []
    for file in tqdm(files, desc=f"Loading {pattern.split('*')[0]}"):
        try:
            df = pd.read_csv(file, sep='$', dtype=str, encoding='utf-8', low_memory=False)
            dfs.append(df)
        except UnicodeDecodeError:
            try:
                df = pd.read_csv(file, sep='$', dtype=str, encoding='latin1', low_memory=False)
                dfs.append(df)
            except Exception as e:
                print(f"Failed to load {file}: {e}")
        except Exception as e:
            print(f"Failed to load {file}: {e}")
    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

df_drug = load_files(data_dir, 'DRUG*.txt')
df_reac = load_files(data_dir, 'REAC*.txt')
print(f"Total DRUG records: {len(df_drug)}")
print(f"Total REACTION records: {len(df_reac)}")

# =============================
# 5️⃣ Preprocessing
# =============================

print("Filtering suspect drugs...")
df_drug_ps = df_drug[df_drug['role_cod'].str.upper() == 'PS'].copy()
df_drug_ps['drugname'] = df_drug_ps['drugname'].fillna('').str.upper()
df_reac['pt'] = df_reac['pt'].fillna('').str.upper()

# Normalize and deduplicate drug names using VigiMatch-style rules

def normalize_name(name):
    if not isinstance(name, str):
        return ''
    name = name.upper()
    for synonym in drug_synonyms:
        if synonym.upper() in name:
            return synonym.upper()
    return name

df_drug_ps['drugname_norm'] = df_drug_ps['drugname'].apply(normalize_name)

# Apply VigiMatch-style deduplication: keep only first entry per (primaryid, drugname_norm, route, dose_vbm)
dedup_columns = ['primaryid', 'drugname_norm', 'route', 'dose_vbm']
df_drug_ps_before = len(df_drug_ps)
df_drug_ps_unique = df_drug_ps.sort_values(by='primaryid').drop_duplicates(subset=dedup_columns)
df_drug_ps_after = len(df_drug_ps_unique)
duplicates_removed_drug = df_drug_ps_before - df_drug_ps_after
print(f" VigiMatch-style DRUG duplicates removed: {duplicates_removed_drug} (from {df_drug_ps_before} → {df_drug_ps_after})")
